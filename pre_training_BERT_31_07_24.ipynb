{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4126afe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mdwivedi/Downloads/core-tech'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9cbd446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e865683",
   "metadata": {
    "id": "ig6jSe2lKVwL"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import BertTokenizer, BertForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f61f321",
   "metadata": {
    "id": "23ogqBdZLST4"
   },
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "# model = BertForPreTraining.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbe193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXECUTION VERSION</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>150705_0</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE BANK OF NOVA SCOTIA</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>150705_1</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as Sole Bookrunner , Lead Arranger and Adminis...</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>150705_2</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- and-</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>150705_3</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMO CAPITAL MARKETS</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>150705_4</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label  index   sent_id  \\\n",
       "0                                  EXECUTION VERSION     B      0  150705_0   \n",
       "1                            THE BANK OF NOVA SCOTIA     B      1  150705_1   \n",
       "2  as Sole Bookrunner , Lead Arranger and Adminis...     B      2  150705_2   \n",
       "3                                             - and-     B      3  150705_3   \n",
       "4                                BMO CAPITAL MARKETS     B      4  150705_4   \n",
       "\n",
       "   topic_id  \n",
       "0      1252  \n",
       "1      1252  \n",
       "2      1252  \n",
       "3      1252  \n",
       "4      1252  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "## Reading the dataframe \n",
    "\n",
    "data = pd.read_csv('due_dilligence_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9418385b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7909065</th>\n",
       "      <td>Exhibit 4.34</td>\n",
       "      <td>B</td>\n",
       "      <td>7909065</td>\n",
       "      <td>217889_0</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909066</th>\n",
       "      <td>€250,000,000 TERM FACILITY AGREEMENT</td>\n",
       "      <td>B</td>\n",
       "      <td>7909066</td>\n",
       "      <td>217889_1</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909067</th>\n",
       "      <td>€250,000,000</td>\n",
       "      <td>B</td>\n",
       "      <td>7909067</td>\n",
       "      <td>217889_2</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909068</th>\n",
       "      <td>TERM FACILITY AGREEMENT</td>\n",
       "      <td>B</td>\n",
       "      <td>7909068</td>\n",
       "      <td>217889_3</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909069</th>\n",
       "      <td>Dated 8 March 2017 for</td>\n",
       "      <td>B</td>\n",
       "      <td>7909069</td>\n",
       "      <td>217889_4</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence label    index   sent_id  \\\n",
       "7909065                          Exhibit 4.34     B  7909065  217889_0   \n",
       "7909066  €250,000,000 TERM FACILITY AGREEMENT     B  7909066  217889_1   \n",
       "7909067                          €250,000,000     B  7909067  217889_2   \n",
       "7909068               TERM FACILITY AGREEMENT     B  7909068  217889_3   \n",
       "7909069                Dated 8 March 2017 for     B  7909069  217889_4   \n",
       "\n",
       "         topic_id  \n",
       "7909065      1469  \n",
       "7909066      1469  \n",
       "7909067      1469  \n",
       "7909068      1469  \n",
       "7909069      1469  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[data['topic_id'] == 1469]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818f85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/hqtjh2m5481_qkt_4p9g5v940000gn/T/ipykernel_46640/1221279264.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df['label'].replace({'B':0, '1':1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7909065</th>\n",
       "      <td>Exhibit 4.34</td>\n",
       "      <td>0</td>\n",
       "      <td>7909065</td>\n",
       "      <td>217889_0</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909066</th>\n",
       "      <td>€250,000,000 TERM FACILITY AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>7909066</td>\n",
       "      <td>217889_1</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909067</th>\n",
       "      <td>€250,000,000</td>\n",
       "      <td>0</td>\n",
       "      <td>7909067</td>\n",
       "      <td>217889_2</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909068</th>\n",
       "      <td>TERM FACILITY AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>7909068</td>\n",
       "      <td>217889_3</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909069</th>\n",
       "      <td>Dated 8 March 2017 for</td>\n",
       "      <td>0</td>\n",
       "      <td>7909069</td>\n",
       "      <td>217889_4</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence  label    index   sent_id  \\\n",
       "7909065                          Exhibit 4.34      0  7909065  217889_0   \n",
       "7909066  €250,000,000 TERM FACILITY AGREEMENT      0  7909066  217889_1   \n",
       "7909067                          €250,000,000      0  7909067  217889_2   \n",
       "7909068               TERM FACILITY AGREEMENT      0  7909068  217889_3   \n",
       "7909069                Dated 8 March 2017 for      0  7909069  217889_4   \n",
       "\n",
       "         topic_id  \n",
       "7909065      1469  \n",
       "7909066      1469  \n",
       "7909067      1469  \n",
       "7909068      1469  \n",
       "7909069      1469  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].replace({'B':0, '1':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06e3601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1252811\n",
       "1       1544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03cd8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/hqtjh2m5481_qkt_4p9g5v940000gn/T/ipykernel_46640/75972406.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['word_count'] = df['sentence'].apply(lambda x: len(str(x).split()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7909065</th>\n",
       "      <td>Exhibit 4.34</td>\n",
       "      <td>0</td>\n",
       "      <td>7909065</td>\n",
       "      <td>217889_0</td>\n",
       "      <td>1469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909066</th>\n",
       "      <td>€250,000,000 TERM FACILITY AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>7909066</td>\n",
       "      <td>217889_1</td>\n",
       "      <td>1469</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909067</th>\n",
       "      <td>€250,000,000</td>\n",
       "      <td>0</td>\n",
       "      <td>7909067</td>\n",
       "      <td>217889_2</td>\n",
       "      <td>1469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909068</th>\n",
       "      <td>TERM FACILITY AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>7909068</td>\n",
       "      <td>217889_3</td>\n",
       "      <td>1469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909069</th>\n",
       "      <td>Dated 8 March 2017 for</td>\n",
       "      <td>0</td>\n",
       "      <td>7909069</td>\n",
       "      <td>217889_4</td>\n",
       "      <td>1469</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence  label    index   sent_id  \\\n",
       "7909065                          Exhibit 4.34      0  7909065  217889_0   \n",
       "7909066  €250,000,000 TERM FACILITY AGREEMENT      0  7909066  217889_1   \n",
       "7909067                          €250,000,000      0  7909067  217889_2   \n",
       "7909068               TERM FACILITY AGREEMENT      0  7909068  217889_3   \n",
       "7909069                Dated 8 March 2017 for      0  7909069  217889_4   \n",
       "\n",
       "         topic_id  word_count  \n",
       "7909065      1469           2  \n",
       "7909066      1469           4  \n",
       "7909067      1469           1  \n",
       "7909068      1469           3  \n",
       "7909069      1469           5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'] = df['sentence'].apply(lambda x: len(str(x).split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb43a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_short_sentences(data):\n",
    "    data = data.dropna()\n",
    "    # Ensure the data is a DataFrame\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"Input must be a pandas DataFrame.\")\n",
    "    \n",
    "    # Check that the necessary columns exist\n",
    "    if 'sentence' not in data.columns or 'label' not in data.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'sentence' and 'label' columns.\")\n",
    "\n",
    "    # Initialize a list to hold the new rows\n",
    "    new_rows = []\n",
    "    # Placeholder for the previous row, if it needs to be merged\n",
    "    previous_row = None\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        # If the sentence is short and there is a previous row, merge them\n",
    "        if len(row['sentence']) <= 50 and previous_row is not None:\n",
    "            previous_row['sentence'] += \" \" + row['sentence']\n",
    "            # Assuming the label merging strategy is to take the label of the first sentence\n",
    "            # Modify as needed, e.g., combine labels, choose max/min, or handle as a list\n",
    "        else:\n",
    "            # If there's a previous row waiting to be added (either merged or not), add it now\n",
    "            if previous_row is not None:\n",
    "                new_rows.append(previous_row)\n",
    "            # Update previous_row to the current row for potential future merging\n",
    "            previous_row = row.copy()\n",
    "\n",
    "    # Add the last row if it wasn't added yet\n",
    "    if previous_row is not None:\n",
    "        new_rows.append(previous_row)\n",
    "\n",
    "    # Create a new DataFrame from the merged rows\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05888f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1252811, 2),\n",
       " label\n",
       " 0    1252811\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = df[df['label'] ==0][['sentence', 'label']]\n",
    "zeros.shape, zeros['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c726c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1544, 2),\n",
       " label\n",
       " 1    1544\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones =  df[df['label'] ==1][['sentence', 'label']]\n",
    "ones.shape, ones['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb948e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575010, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7909065</th>\n",
       "      <td>Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...</td>\n",
       "      <td>0</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909137</th>\n",
       "      <td>26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909187</th>\n",
       "      <td>Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909189</th>\n",
       "      <td>( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909191</th>\n",
       "      <td>as original guarantor ( the \" Original Guarant...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence  label  \\\n",
       "7909065  Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...      0   \n",
       "7909137  26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...      0   \n",
       "7909187  Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...      0   \n",
       "7909189  ( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...      0   \n",
       "7909191  as original guarantor ( the \" Original Guarant...      0   \n",
       "\n",
       "         sentence_length  \n",
       "7909065              949  \n",
       "7909137              914  \n",
       "7909187              139  \n",
       "7909189              102  \n",
       "7909191               54  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_zeros = merge_short_sentences(zeros)\n",
    "processed_data_zeros['sentence_length'] = processed_data_zeros['sentence'].str.len()\n",
    "print(processed_data_zeros.shape)\n",
    "processed_data_zeros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff4d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8963154       51\n",
       "8137057       51\n",
       "8825153       51\n",
       "8025536       51\n",
       "8422972       51\n",
       "           ...  \n",
       "8433105    35289\n",
       "8429771    43786\n",
       "8502267    51655\n",
       "8016247    76132\n",
       "8493973    90922\n",
       "Name: sentence_length, Length: 575010, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_zeros['sentence_length'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8d8ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(802, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7912788</th>\n",
       "      <td>( a ) Each Borrower agrees to pay , in US Doll...</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912789</th>\n",
       "      <td>provided , that if any Lender continues to hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912790</th>\n",
       "      <td>Accrued facility fees shall be payable in arre...</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912791</th>\n",
       "      <td>provided that any facility fees accruing on th...</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912792</th>\n",
       "      <td>All facility fees shall be computed on the bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence  label  \\\n",
       "7912788  ( a ) Each Borrower agrees to pay , in US Doll...      1   \n",
       "7912789  provided , that if any Lender continues to hav...      1   \n",
       "7912790  Accrued facility fees shall be payable in arre...      1   \n",
       "7912791  provided that any facility fees accruing on th...      1   \n",
       "7912792  All facility fees shall be computed on the bas...      1   \n",
       "\n",
       "         sentence_length  \n",
       "7912788              618  \n",
       "7912789              456  \n",
       "7912790              320  \n",
       "7912791              200  \n",
       "7912792              207  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_ones = merge_short_sentences(ones)\n",
    "processed_data_ones['sentence_length'] = processed_data_ones['sentence'].str.len()\n",
    "print(processed_data_ones.shape)\n",
    "processed_data_ones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a55cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_zeros = processed_data_zeros.reset_index(drop=True)\n",
    "processed_data_ones = processed_data_ones.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae37d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(575812, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...</td>\n",
       "      <td>0</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...</td>\n",
       "      <td>0</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as original guarantor ( the \" Original Guarant...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  sentence_length\n",
       "0  Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...      0              949\n",
       "1  26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...      0              914\n",
       "2  Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...      0              139\n",
       "3  ( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...      0              102\n",
       "4  as original guarantor ( the \" Original Guarant...      0               54"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.concat([processed_data_zeros, processed_data_ones]).reset_index(drop =True)\n",
    "print(combined_data.shape)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d232cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as original guarantor ( the \" Original Guarant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...\n",
       "1  26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...\n",
       "2  Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...\n",
       "3  ( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...\n",
       "4  as original guarantor ( the \" Original Guarant..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(combined_data['sentence']) \n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28740eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 3), (100, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_zeros_sampled = processed_data_zeros[:100]\n",
    "processed_data_ones_sampled  = processed_data_ones[:100]\n",
    "processed_data_zeros_sampled.shape, processed_data_ones_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d25b53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as original guarantor ( the \" Original Guarant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...\n",
       "1  26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...\n",
       "2  Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...\n",
       "3  ( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...\n",
       "4  as original guarantor ( the \" Original Guarant..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_2 = pd.concat([processed_data_zeros_sampled, processed_data_ones_sampled]).reset_index(drop = True)\n",
    "final_data_2 = pd.DataFrame(final_data_2['sentence'])\n",
    "final_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2aab60",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "459f2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(final_data_2)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'test': train_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44b8fea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence'],\n",
       "        num_rows: 180\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11705bc",
   "metadata": {},
   "source": [
    "## Step 3: Set Up the BERT Model for MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95c9830a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-cased')\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede085e",
   "metadata": {},
   "source": [
    "## Step 4: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ccb3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=True,  # Enables MLM\n",
    "    mlm_probability=0.15  # 15% of tokens will be masked on average\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c6a95d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Assumes your text data is under the key 'sentence'\n",
    "    return tokenizer(examples['sentence'], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'token_type_ids'])  # 'labels' are not statically set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0deb740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
    "train_dataloader = DataLoader(dataset['train'], collate_fn=data_collator, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be17f4",
   "metadata": {},
   "source": [
    "## Step 5: Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4e7ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_pretrained\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"no\",  # No checkpoints saved automatically\n",
    "#     evaluation_strategy=\"no\",  # No evaluation if you don't need it\n",
    "    report_to=\"all\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset['train'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d335aa6",
   "metadata": {},
   "source": [
    "## Step 6: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8aa012f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45, training_loss=0.022048101160261367, metrics={'train_runtime': 51.7882, 'train_samples_per_second': 3.476, 'train_steps_per_second': 0.869, 'total_flos': 47376022487040.0, 'train_loss': 0.022048101160261367, 'epoch': 1.0})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee4c8126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mdwivedi/Downloads/core-tech'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe16c8f",
   "metadata": {},
   "source": [
    "## MLM accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b78985c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mlm_accuracy(model, tokenizer, dataset, device):\n",
    "    model.eval()\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=64, collate_fn=data_collator)\n",
    "    correct_predictions = total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask', 'labels']}\n",
    "            outputs = model(**batch)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            labels = batch['labels']\n",
    "\n",
    "            mask = labels != -100  # Ignore padding tokens\n",
    "            correct_predictions += (predictions[mask] == labels[mask]).sum().item()\n",
    "            total_predictions += mask.sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    model.train()  # Make sure to reset model to training mode\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b38b3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLM Accuracy: 0.6884\n"
     ]
    }
   ],
   "source": [
    "eval_dataset=dataset['test']\n",
    "accuracy = compute_mlm_accuracy(model, tokenizer, eval_dataset, model.device)\n",
    "print(f\"MLM Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e114308",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3da904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./bert_model_1469_pretrained\")\n",
    "tokenizer.save_pretrained(\"./bert_model_1469_pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8faea",
   "metadata": {},
   "source": [
    "## NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f14915c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0e01539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForLanguageModeling, BertTokenizer\n",
    "\n",
    "# # Initialize the data collator\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer,\n",
    "#     mlm=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34298326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at ./embedding_model_comparision/bert_model_1469_pretrained_MLM and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "\n",
    "# Path to your saved model and tokenizer\n",
    "model_path = \"./embedding_model_comparision/bert_model_1469_pretrained_MLM\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForPreTraining.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d93e6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_balanced_sentence_pairs(sentences):\n",
    "    consecutive_pairs = [(sentences[i], sentences[i + 1], 1) for i in range(len(sentences) - 1)]\n",
    "\n",
    "    # Generating non-consecutive pairs\n",
    "    non_consecutive_pairs = []\n",
    "    while len(non_consecutive_pairs) < len(consecutive_pairs):\n",
    "        i, j = random.sample(range(len(sentences)), 2)\n",
    "        if abs(i - j) > 1:  # Ensure that the pair is not consecutive\n",
    "            non_consecutive_pairs.append((sentences[i], sentences[j], 0))\n",
    "\n",
    "    # Combine and shuffle\n",
    "    all_pairs = consecutive_pairs + non_consecutive_pairs\n",
    "    random.shuffle(all_pairs)\n",
    "\n",
    "    return all_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "985fe575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as original guarantor ( the \" Original Guarant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  Exhibit 4.34 €250,000,000 TERM FACILITY AGREEM...\n",
       "1  26 . ROLE OF THE AGENT AND THE MANDATED LEAD A...\n",
       "2  Schedule 13 CONDITIONS PRECEDENT REQUIRED TO B...\n",
       "3  ( 1 ) LUXOTTICA GROUP S.p.A. , as borrower ( t...\n",
       "4  as original guarantor ( the \" Original Guarant..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36af1917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_a</th>\n",
       "      <th>sentence_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom , any member state of the Europ...</td>\n",
       "      <td>( e ) commercial paper not convertible or exch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anti-Money Laundering Laws \" means the Executi...</td>\n",
       "      <td>The Borrower agrees to pay to the Administrati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Confidential Information \" means all informati...</td>\n",
       "      <td>( b ) The Borrowers shall pay to the Agent , f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( c ) with respect to which an Insolvency Even...</td>\n",
       "      <td>and payment is made within 5 Business Days of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facility Fee accruing from and after the Closi...</td>\n",
       "      <td>The Unused Facility Fee will be calculated and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentence_a  \\\n",
       "0  United Kingdom , any member state of the Europ...   \n",
       "1  Anti-Money Laundering Laws \" means the Executi...   \n",
       "2  Confidential Information \" means all informati...   \n",
       "3  ( c ) with respect to which an Insolvency Even...   \n",
       "4  Facility Fee accruing from and after the Closi...   \n",
       "\n",
       "                                          sentence_b  label  \n",
       "0  ( e ) commercial paper not convertible or exch...      1  \n",
       "1  The Borrower agrees to pay to the Administrati...      0  \n",
       "2  ( b ) The Borrowers shall pay to the Agent , f...      0  \n",
       "3  and payment is made within 5 Business Days of ...      1  \n",
       "4  The Unused Facility Fee will be calculated and...      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(create_balanced_sentence_pairs(final_data_2['sentence']))\n",
    "train_data.columns = ['sentence_a', 'sentence_b', 'label']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21182e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting data\n",
    "train_df, val_df = train_test_split(train_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca7e7c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def tokenize_nsp(examples):\n",
    "    sentence_a = examples['sentence_a']\n",
    "    sentence_b = examples['sentence_b']\n",
    "    # Tokenize each pair and ensure that the total length does not exceed the max_length\n",
    "    tokenized_input = tokenizer(sentence_a, sentence_b, \n",
    "                                padding=\"max_length\",  # Ensures all outputs are padded to max_length\n",
    "                                truncation=True,       # Ensures truncation to fit the max_length\n",
    "                                max_length=512,        # Define max_length according to your model capacity\n",
    "                                return_tensors=\"pt\")\n",
    "    return tokenized_input\n",
    "\n",
    "\n",
    "# Create Hugging Face dataset\n",
    "# Convert to Hugging Face dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# Map tokenization\n",
    "train_dataset = train_dataset.map(tokenize_nsp, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d69677f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence_a', 'sentence_b', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 358\n",
       "})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9c58a45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "154994a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert_nsp_trained',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_dir='./logs_nsp',\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"all\"\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs['seq_relationship_logits']\n",
    "        labels = inputs.get(\"labels\")\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "        else:\n",
    "            return (None, outputs) if return_outputs else None\n",
    "\n",
    "# Then use CustomTrainer instead of Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c6010d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90/90 01:23, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90, training_loss=0.4987948947482639, metrics={'train_runtime': 84.4072, 'train_samples_per_second': 4.241, 'train_steps_per_second': 1.066, 'total_flos': 94876855087104.0, 'train_loss': 0.4987948947482639, 'epoch': 1.0})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f700d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_nsp_1(data):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        data['sentence_a'], data['sentence_b'], \n",
    "        add_special_tokens=True, \n",
    "        return_tensors='pt',\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': inputs['input_ids'].squeeze(0),  # Remove the batch dimension\n",
    "        'token_type_ids': inputs['token_type_ids'].squeeze(0),\n",
    "        'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "        'next_sentence_label': torch.tensor(data['label'])  # Assuming label is 0 or 1\n",
    "    }\n",
    "\n",
    "# Apply tokenization and prepare the DataLoader\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "val_dataset = val_dataset.map(tokenize_nsp_1, remove_columns=val_dataset.column_names)\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label'])\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "193c2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation NSP Accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "def calculate_nsp_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    correct_preds, num_samples = 0, 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to the correct device\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            nsp_logits = outputs.seq_relationship_logits  # Correct attribute for NSP predictions\n",
    "            predictions = torch.argmax(nsp_logits, dim=1)\n",
    "            correct_preds += (predictions == batch['next_sentence_label']).sum().item()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    accuracy = correct_preds / num_samples if num_samples > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy on validation dataset\n",
    "val_accuracy = calculate_nsp_accuracy(model, val_dataloader)\n",
    "print(f\"Validation NSP Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./bert_model_1469_pretrained_nsp\")\n",
    "tokenizer.save_pretrained(\"./bert_model_1469_pretrained_nsp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca3fb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mdwivedi/Downloads/core-tech'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd82e1",
   "metadata": {},
   "source": [
    "## Finetuning on same topic 1469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b51c222d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXECUTION VERSION</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>150705_0</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE BANK OF NOVA SCOTIA</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>150705_1</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as Sole Bookrunner , Lead Arranger and Adminis...</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>150705_2</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- and-</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>150705_3</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMO CAPITAL MARKETS</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>150705_4</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label  index   sent_id  \\\n",
       "0                                  EXECUTION VERSION     B      0  150705_0   \n",
       "1                            THE BANK OF NOVA SCOTIA     B      1  150705_1   \n",
       "2  as Sole Bookrunner , Lead Arranger and Adminis...     B      2  150705_2   \n",
       "3                                             - and-     B      3  150705_3   \n",
       "4                                BMO CAPITAL MARKETS     B      4  150705_4   \n",
       "\n",
       "   topic_id  \n",
       "0      1252  \n",
       "1      1252  \n",
       "2      1252  \n",
       "3      1252  \n",
       "4      1252  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading data\")\n",
    "df = pd.read_csv('due_dilligence_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa52a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXECUTION VERSION</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>150705_0</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE BANK OF NOVA SCOTIA</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>150705_1</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as Sole Bookrunner , Lead Arranger and Adminis...</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>150705_2</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- and-</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>150705_3</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMO CAPITAL MARKETS</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>150705_4</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label  index   sent_id  \\\n",
       "0                                  EXECUTION VERSION     B      0  150705_0   \n",
       "1                            THE BANK OF NOVA SCOTIA     B      1  150705_1   \n",
       "2  as Sole Bookrunner , Lead Arranger and Adminis...     B      2  150705_2   \n",
       "3                                             - and-     B      3  150705_3   \n",
       "4                                BMO CAPITAL MARKETS     B      4  150705_4   \n",
       "\n",
       "   topic_id  \n",
       "0      1252  \n",
       "1      1252  \n",
       "2      1252  \n",
       "3      1252  \n",
       "4      1252  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22283fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/hqtjh2m5481_qkt_4p9g5v940000gn/T/ipykernel_1082/952703032.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label'].replace({'B': 0, '1': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7909065</th>\n",
       "      <td>Exhibit 4.34</td>\n",
       "      <td>0</td>\n",
       "      <td>7909065</td>\n",
       "      <td>217889_0</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909066</th>\n",
       "      <td>€250,000,000 TERM FACILITY AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>7909066</td>\n",
       "      <td>217889_1</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909067</th>\n",
       "      <td>€250,000,000</td>\n",
       "      <td>0</td>\n",
       "      <td>7909067</td>\n",
       "      <td>217889_2</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909068</th>\n",
       "      <td>TERM FACILITY AGREEMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>7909068</td>\n",
       "      <td>217889_3</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909069</th>\n",
       "      <td>Dated 8 March 2017 for</td>\n",
       "      <td>0</td>\n",
       "      <td>7909069</td>\n",
       "      <td>217889_4</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence  label    index   sent_id  \\\n",
       "7909065                          Exhibit 4.34      0  7909065  217889_0   \n",
       "7909066  €250,000,000 TERM FACILITY AGREEMENT      0  7909066  217889_1   \n",
       "7909067                          €250,000,000      0  7909067  217889_2   \n",
       "7909068               TERM FACILITY AGREEMENT      0  7909068  217889_3   \n",
       "7909069                Dated 8 March 2017 for      0  7909069  217889_4   \n",
       "\n",
       "         topic_id  \n",
       "7909065      1469  \n",
       "7909066      1469  \n",
       "7909067      1469  \n",
       "7909068      1469  \n",
       "7909069      1469  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[df['topic_id'] == 1469]\n",
    "data['label'] = data['label'].replace({'B': 0, '1': 1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434a9146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/hqtjh2m5481_qkt_4p9g5v940000gn/T/ipykernel_1082/1977311852.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentence'] = data['sentence'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "data['sentence'] = data['sentence'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "877cbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.3, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d449de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.label.value_counts(), test_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c08ff0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to Hugging Face's Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5465d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing...\")\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer_path = \"./embedding_model_comparision/bert_model_1469_pretrained_nsp\"\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8177893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431ea4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./embedding_model_comparision/bert_model_1469_pretrained_nsp and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./embedding_model_comparision/bert_model_1469_pretrained_nsp\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef30c5fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b9ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, np.ndarray):\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "    else:\n",
    "        predictions = logits.argmax(axis=-1)\n",
    "        predictions = predictions.detach().cpu().numpy()  # Ensure conversion only if it's a tensor\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    # Calculate the classification report\n",
    "    full_report = classification_report(labels, predictions, target_names=['Class 0', 'Class 1'], output_dict=True)\n",
    "    \n",
    "    return {'full_classification_report': full_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c88377a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_output\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     load_best_model_at_end=True\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# training_args = TrainingArguments(\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     output_dir='./model_output',\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     num_train_epochs=3,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     report_to=\"none\"  # Simplify by turning off reporting\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     25\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     26\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[1;32m     27\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     28\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:409\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_accelerator_and_postprocess()\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:4648\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4645\u001b[0m     args\u001b[38;5;241m.\u001b[39mupdate(accelerator_config)\n\u001b[1;32m   4647\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 4648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m Accelerator(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   4649\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:471\u001b[0m, in \u001b[0;36mAccelerator.__init__\u001b[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, dispatch_batches, even_batches, use_seedable_sampler, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnative_amp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusa\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_xla_available(\n\u001b[1;32m    469\u001b[0m     check_is_tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    470\u001b[0m ):\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16 mixed precision requires a GPU (not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    472\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler\u001b[38;5;241m.\u001b[39mto_kwargs() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mFSDP:\n",
      "\u001b[0;31mValueError\u001b[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model_output',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs',\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"all\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training started\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918345b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "full_report = results['full_classification_report']\n",
    "\n",
    "print(\"Full Classification Report:\")\n",
    "for label, metrics in full_report.items():\n",
    "    if isinstance(metrics, dict):  # This ensures we're only looking at class metrics\n",
    "        print(f\"Label: {label}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        print()  # Adds a newline for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32311eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./bert_1469_finetuned_classification')\n",
    "tokenizer.save_pretrained('./bert_1469_finetuned_classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
